<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>Dreamgazer</title><meta name="robots" content="index,follow"/><meta name="description" content="undefined"/><meta property="og:title" content="Dreamgazer"/><meta property="og:description" content="undefined"/><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"/><link rel="manifest" href="/favicon/site.webmanifest"/><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#000000"/><link rel="shortcut icon" href="/favicon/favicon.ico"/><meta name="msapplication-TileColor" content="#000000"/><meta name="msapplication-config" content="/favicon/browserconfig.xml"/><meta name="theme-color" content="#000"/><link rel="alternate" type="application/rss+xml" href="/feed.xml"/><meta property="og:image" content="https://og-image.vercel.app/Next.js%20Blog%20Starter%20Example.png?theme=light&amp;md=1&amp;fontSize=100px&amp;images=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Ffront%2Fassets%2Fdesign%2Fnextjs-black-logo.svg"/><meta name="next-head-count" content="18"/><link rel="preload" href="https://jddunn.github.io/_next/static/css/102311681b07b408.css" as="style"/><link rel="stylesheet" href="https://jddunn.github.io/_next/static/css/102311681b07b408.css" data-n-g=""/><link rel="preload" href="https://jddunn.github.io/_next/static/css/3116167ddf16f948.css" as="style"/><link rel="stylesheet" href="https://jddunn.github.io/_next/static/css/3116167ddf16f948.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="https://jddunn.github.io/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="https://jddunn.github.io/_next/static/chunks/webpack-ce5f0ec9e7a9015e.js" defer=""></script><script src="https://jddunn.github.io/_next/static/chunks/framework-2c79e2a64abdb08b.js" defer=""></script><script src="https://jddunn.github.io/_next/static/chunks/main-a028e25a41b5197e.js" defer=""></script><script src="https://jddunn.github.io/_next/static/chunks/pages/_app-f06f56473160e3e4.js" defer=""></script><script src="https://jddunn.github.io/_next/static/chunks/424-a679efd82258b30d.js" defer=""></script><script src="https://jddunn.github.io/_next/static/chunks/283-26f9239c83fd4f05.js" defer=""></script><script src="https://jddunn.github.io/_next/static/chunks/478-04308f6dd89c78fb.js" defer=""></script><script src="https://jddunn.github.io/_next/static/chunks/pages/projects/%5Bslug%5D-2b2fc9a6750ed450.js" defer=""></script><script src="https://jddunn.github.io/_next/static/KN6swUZf51tb_txjAh-fx/_buildManifest.js" defer=""></script><script src="https://jddunn.github.io/_next/static/KN6swUZf51tb_txjAh-fx/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="Navbar_navbar__VkIDk"><nav><section class="mobile-menu md:hidden"><div class="hamburger-icon space-y-2 mt-5 mr-5" style="cursor:pointer;position:fixed;top:0;right:0;margin:20"><span class="block h-0.5 w-8 animate-pulse bg-gray-600"></span><span class="block h-0.5 w-8 animate-pulse bg-gray-600"></span><span class="block h-0.5 w-8 animate-pulse bg-gray-600"></span></div><div class="hideMenuNav"><div class="absolute top-0 right-0 px-8 py-8" style="cursor:pointer"><svg class="h-8 w-8 text-gray-600" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="cursor:pointer"><line x1="18" y1="6" x2="6" y2="18"></line><line x1="6" y1="6" x2="18" y2="18"></line></svg></div><ul class="flex flex-col items-center justify-between min-h-[250px]"><a href="/"><li class="border-b border-gray-400 my-8 uppercase" style="margin-left:0px">HOME</li></a><a href="/about/"><li class="border-b border-gray-400 my-8 uppercase" style="margin-left:0px">ABOUT ME</li></a><a href="/projects/"><li class="border-b border-gray-400 my-8 uppercase" style="margin-left:0px">PROJECTS</li></a><a href="/open-source/"><li class="border-b border-gray-400 my-8 uppercase" style="margin-left:0px">OPEN SOURCE</li></a><a href="/blog/"><li class="border-b border-gray-400 my-8 uppercase" style="margin-left:0px">BLOG</li></a></ul></div></section><ul class="desktop-menu hidden md:flex"><a href="/"><li class="" style="margin-left:0px">__home</li></a><a href="/about/"><li class="" style="margin-left:0px">__about me</li></a><a href="/projects/"><li class="Navbar_active___L3RU" style="margin-left:0px">__projects</li></a><a href="/open-source/"><li class="" style="margin-left:0px">__open source</li></a><a href="/blog/"><li class="" style="margin-left:0px">__blog</li></a></ul></nav><style>
        .hideMenuNav {
          display: none;
        }
        .showMenuNav {
          display: block;
          position: absolute;
          width: 100%;
          min-height: 400px;
          top: 20;
          right: 20;
          z-index: 10;
          display: flex;
          flex-direction: column;
        }
        .mobile-menu ul {
          background-color: rgba(2, 10, 18, 0.95)
        }
    </style></div><div class="min-h-screen"><main><div class="container mx-auto px-5"><h2 class="text-1xl md:text-2xl lg:text-3xl font-bold tracking-tight  md:tracking-tighter leading-tight mb-20 mt-8"></h2><article class="mb-32"><div><h1 class="text-2xl md:text-2xl lg:text-3xl font-bold  tracking-tighter leading-tight md:leading-none mb-12  text-center"><span class="text-2xl md:text-2xl lg:text-3xl red-400 inline tracking-tighter leading-tight md:leading-none mb-12 text-center text-gray-400 mr-2">//</span>Dreamgazer</h1><div class="mb-0"><div class="text-md text-slate-500 text-center">Project created: <time dateTime="2017">2017</time></div><div class="text-md text-slate-200 mb-3 backButton"><button><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M8 0a8 8 0 1 0 0 16A8 8 0 0 0 8 0zm3.5 7.5a.5.5 0 0 1 0 1H5.707l2.147 2.146a.5.5 0 0 1-.708.708l-3-3a.5.5 0 0 1 0-.708l3-3a.5.5 0 1 1 .708.708L5.707 7.5H11.5z"></path></svg></button></div></div><div class="text-md text-slate-500 text-center">Post updated: <time dateTime="2017">2017</time></div><div class="mb-8 md:mb-16 sm:mx-0 mt-5"><div class="sm:mx-0"><div class="relative mx-auto"><img alt="Cover Image for Dreamgazer" loading="lazy" width="600" height="480" decoding="async" data-nimg="1" class="shadow-lg dark:shadow-black/30 mx-auto" style="color:transparent" src="/assets/projects/lucid-dream-data-visualization.png"/></div></div><div class="text-sm text-slate-500 mb-4 mt-2 text-center"><span class="mr-5 underline">lucid dreams</span><span class="mr-5 underline">EEG</span><span class="mr-5 underline">brain-computer interface</span><span class="mr-5 underline">biotech</span><span class="mr-5 underline">processing</span></div></div><div class="max-w-2xl mx-auto"></div></div><div class="max-w-2xl mx-auto"><div class="markdown-styles_markdown__9bgXN"><p><a class="md-link" href="https://jddunn.github.io/rough-copies/" style="text-align: center" target="_blank">Rough Copies - Old Research Documentation Site</a></p>
<h2 id="intro">Intro</h2>
<p>Dreamgazer so far embodies a series of projects and research experiments I have been undertaking since my later years of high school. These works include:</p>
<ul>
<li><p>A several month long journey in high school to produce a illustrated dream journal containing experiment documentation and dream analyses, to show the progression of lucid dream training (2011)</p></li>
<li><p>A brain-computer interface prototype (built by hacking apart the NeuroSky MindWave) able to successfully detect when someone fell asleep within a period of a few minutes, and also able to induce lucid dreaming within myself by playing a trained musical trigger during the appropriate dreaming stages of REM (2015)</p></li>
<li><p>A 3D printable wearable device with various sensors, electrodes, and a VR interface meant to induce the "ultimate" lucid dreams (2017)</p></li>
</ul>
<h2 id="thedreamingmachine">The dreaming machine</h2>
<p><a href="/assets/projects/dreamgazer-prototype-front.jpg" target="_blank"><img src="/assets/projects/dreamgazer-prototype-front.jpg" class="img-shadow" style="display: block; margin-left: auto; margin-right: auto;" width="400" alt="Dreamgazer brain-computer interface prototype for lucid dreaming"></img></a></p>
<p>In 2015, I made a wearable prototype to induce lucid dreaming using an Arduino, a pulse sensor, the NeuroSky MindWave (EEG), and Processing (for software). I was able to detect when I fell asleep within an accuracy of just a few minutes, and was able to successfully induce lucid dreaming by playing music during detected stages of REM sleep (by measuring eye movement after sleep).</p>
<p><a href="/assets/projects/lucid-dream-data-visualization.png" target="_blank"><img src="/assets/projects/lucid-dream-data-visualization.png" class="img-shadow" style="display: block; margin-left: auto; margin-right: auto;" width="500" alt="Dreamgazer brain-computer interface prototype for lucid dreaming"></img></a>
<span style="text-align: center; color: grey; margin-left: auto; margin-right: auto; display: block; width: 80%">Image still from an abstract visual recording of a dream by tracking biometric patterns (eye movement, heart rate, and EEG waves)</span></p>
<p>I chose to use Processing because it already had compatible libraries with all the open-source hardware I was using, and because of Processing's simple and immediate way of writng animations. The visualization of dreams through biometric and EEG data was something I really wanted to nail.</p>
<iframe src="https://www.youtube.com/embed/N_l1COTufZE?rel=0" width="100%" height="315em" frameborder="0" allowfullscreen></iframe>
<span style="text-align: center; color: grey; margin-left: auto; margin-right: auto; display: block; width: 80%">Video demonstration of wearable prototype in use, with software recording dream in real-time and playing musical triggers during REM sleep</span></p>
<h2 id="theresults">The Results</h2>
<p>I was able to detect when I fell asleep within an accuracy of five minutes, and was able to successfully induce lucid dreaming by playing music when REM sleep was detected.</p>
<p>I used Processing to visualize my dreams and record my biometric data over the course of several different nights. The data was automatically fed into a spreadsheet for easy analysis.</p>
<p>You can see and use the data yourself <a class="md-link" href="https://docs.google.com/spreadsheets/d/1Y8HOtzMYF8cwWqB92FebTu3TLxZ9siHHUTT_H1PWqZM/edit?usp=sharing" target="_blank" style="margin-left: 0; margin-right: 0; display: inline">here</a> (if the data does turn out to be useful for people, I'll go back and separate it into each night to organize).</p>
<p><a href="/assets/projects/dream_spreadsheet_data.png" target="_blank"><img src="/assets/projects/dream_spreadsheet_data.png" class="img-shadow" style="display: block; margin-left: auto; margin-right: auto;" width="500" alt="Dream data spreadsheet"></img></a></p>
<p>Below you'll see annotated graphs demonstrating the success of the device, recording biometric and EEG trends corresponding with points of interest throughout a night of dreaming.</p>
<p><a href="/assets/projects/DreamGazer%20Early%20Prototype%20with%20MindWave%20-%20Success%20Trial%20Night%201%20-%20Close%20Look%20Chart.png" target="_blank"><img src="/assets/projects/DreamGazer%20Early%20Prototype%20with%20MindWave%20-%20Success%20Trial%20Night%201%20-%20Close%20Look%20Chart.png" class="img-shadow" style="display: block; margin-left: auto; margin-right: auto;" width="500" alt="Dream data success trial night 1 graph"></img></a></p>
<p><a href="/assets/projects/DreamGazer%20Early%20Prototype%20with%20MindWave%20-%20Success%20Trial%20Night%202%20(Full%20Log).png" target="_blank"><img src="/assets/projects/DreamGazer%20Early%20Prototype%20with%20MindWave%20-%20Success%20Trial%20Night%202%20(Full%20Log).png" class="img-shadow" style="display: block; margin-left: auto; margin-right: auto;" width="500" alt="Dream data success trial night 2 graph"></img></a></p>
<p><a href="/assets/projects/DreamGazer%20Early%20Prototype%20with%20MindWave%20-%20Success%20Trial%20Night%203%20-%20Close%20Look.png" target="_blank"><img src="/assets/projects/DreamGazer%20Early%20Prototype%20with%20MindWave%20-%20Success%20Trial%20Night%203%20-%20Close%20Look.png" class="img-shadow" style="display: block; margin-left: auto; margin-right: auto;" width="500" alt="Dream data success trial night 3 graph"></img></a></p>
<h2 id="thefutureconcept">The future concept</h2>
<p>The name Dreamgazer refers specifically to a mostly conceptualized, combined VR / AR, EEG, and tDCS (transcranial direct current stimulation) device designed to be 3D printed and then hand-assembled. Dreamgazer's software was planned to be integrated with an AI program (Emoter) that would train users to dream, and guide them through their dreams vocally by talking and responding to biofeedback.</p>
<p><a href="/assets/projects/DreamGazer-3D-Front.png" target="_blank"><img src="/assets/projects/DreamGazer-3D-Front.png" class="img-shadow" style="display: block; margin-left: auto; margin-right: auto;" width="500" alt="Dreamgazer 3D front"></img></a></p>
<p><a href="/assets/projects/DreamGazer-Diagram.jpg" target="_blank"><img src="/assets/projects/DreamGazer-Diagram.jpg" class="img-shadow" style="display: block; margin-left: auto; margin-right: auto;" width="600" alt="Dreamgazer components diagram"></img></a>
<span style="text-align: center; color: grey; margin-left: auto; margin-right: auto; display: block; width: 80%">The plans were made to be functional, and hand-assembled with proper construction and fabric materials.</span></p>
<p><a href="/assets/projects/dreamgazer-intro.png" target="_blank"><img src="/assets/projects/dreamgazer-intro.png" class="img-shadow" style="display: block; margin-left: auto; margin-right: auto;" width="500" alt="Dreamgazer VR UI intro"></img></a>
<span style="text-align: center; color: grey; margin-left: auto; margin-right: auto; display: block; width: 80%">The plans were made to be functional, and hand-assembled with proper construction and fabric materials.</span></p>
<iframe src="https://www.youtube.com/embed/rFekLHHXhHs?rel=0" width="100%" height="315em" frameborder="0" allowfullscreen></iframe>
<span style="text-align: center; color: grey; margin-left: auto; margin-right: auto; display: block; width: 80%">Dreamgazer was designed with a VR interface, in Unity.</span></p>
<p><a href="/assets/projects/DreamGazer-Main-Flowchart.png" target="_blank"><img src="/assets/projects/DreamGazer-Main-Flowchart.png" class="img-shadow" style="display: block; margin-left: auto; margin-right: auto;" width="500" alt="DreamGazer main flowchart"></img></a>
<span style="text-align: center; color: grey; margin-left: auto; margin-right: auto; display: block; width: 80%">The full step-by-step process of Dreamgazer's proposed functionality.</span></p>
<p>Lucid dreaming in wearables and biotechnology is something I will continue exploring. I have plans to further develop and refine new iterations of Dreamgazer, and would like to be able to open-source the hardware and software.</p></div></div></article></div></main></div><div class="Footer_footer__BH5s_"><div><p class="Footer_find__pDm3T" style="letter-spacing:2px">find me on:</p><a href="https://www.linkedin.com/in/jdfive/" target="_blank" rel="noopener noreferrer"><span class="Footer_footerIcon__bo_UL"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854V1.146zm4.943 12.248V6.169H2.542v7.225h2.401zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248-.822 0-1.359.54-1.359 1.248 0 .694.521 1.248 1.327 1.248h.016zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016a5.54 5.54 0 0 1 .016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225h2.4z"></path></svg></span></a><a href="https://github.com/jddunn" target="_blank" rel="noopener noreferrer"><span class="Footer_footerIcon__bo_UL"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z"></path></svg></span></a></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"Dreamgazer","date":"2017","createdDate":"2017","slug":"dreamgazer","tags":"lucid dreams,EEG,brain-computer interface,biotech,processing","content":"\n\u003ca class=\"md-link\" href=\"https://jddunn.github.io/rough-copies/\" style=\"text-align: center\" target=\"_blank\"\u003eRough Copies - Old Research Documentation Site\u003c/a\u003e\n\n## Intro\n\nDreamgazer so far embodies a series of projects and research experiments I have been undertaking since my later years of high school. These works include:\n\n* A several month long journey in high school to produce a illustrated dream journal containing experiment documentation and dream analyses, to show the progression of lucid dream training (2011)\n\n* A brain-computer interface prototype (built by hacking apart the NeuroSky MindWave) able to successfully detect when someone fell asleep within a period of a few minutes, and also able to induce lucid dreaming within myself by playing a trained musical trigger during the appropriate dreaming stages of REM (2015)\n\n* A 3D printable wearable device with various sensors, electrodes, and a VR interface meant to induce the \"ultimate\" lucid dreams (2017)\n\n## The dreaming machine\n\n\u003ca href=\"/assets/projects/dreamgazer-prototype-front.jpg\" target=\"_blank\"\u003e\u003cimg src=\"/assets/projects/dreamgazer-prototype-front.jpg\" class=\"img-shadow\" style=\"display: block; margin-left: auto; margin-right: auto;\" width=\"400\" alt=\"Dreamgazer brain-computer interface prototype for lucid dreaming\"\u003e\u003c/img\u003e\u003c/a\u003e\n\nIn 2015, I made a wearable prototype to induce lucid dreaming using an Arduino, a pulse sensor, the NeuroSky MindWave (EEG), and Processing (for software). I was able to detect when I fell asleep within an accuracy of just a few minutes, and was able to successfully induce lucid dreaming by playing music during detected stages of REM sleep (by measuring eye movement after sleep).\n\n\u003ca href=\"/assets/projects/lucid-dream-data-visualization.png\" target=\"_blank\"\u003e\u003cimg src=\"/assets/projects/lucid-dream-data-visualization.png\" class=\"img-shadow\" style=\"display: block; margin-left: auto; margin-right: auto;\" width=\"500\" alt=\"Dreamgazer brain-computer interface prototype for lucid dreaming\"\u003e\u003c/img\u003e\u003c/a\u003e\n\u003cspan style=\"text-align: center; color: grey; margin-left: auto; margin-right: auto; display: block; width: 80%\"\u003eImage still from an abstract visual recording of a dream by tracking biometric patterns (eye movement, heart rate, and EEG waves)\u003c/span\u003e\n\nI chose to use Processing because it already had compatible libraries with all the open-source hardware I was using, and because of Processing's simple and immediate way of writng animations. The visualization of dreams through biometric and EEG data was something I really wanted to nail.\n\n![Dreamgazer brain-computer interface UI demo on youtube](https://www.youtube.com/watch?v=N_l1COTufZE\u0026t=15s =100%x315em)\n\u003cspan style=\"text-align: center; color: grey; margin-left: auto; margin-right: auto; display: block; width: 80%\"\u003eVideo demonstration of wearable prototype in use, with software recording dream in real-time and playing musical triggers during REM sleep\u003c/span\u003e\n\n## The Results\n\nI was able to detect when I fell asleep within an accuracy of five minutes, and was able to successfully induce lucid dreaming by playing music when REM sleep was detected.\n\nI used Processing to visualize my dreams and record my biometric data over the course of several different nights. The data was automatically fed into a spreadsheet for easy analysis.\n\nYou can see and use the data yourself \u003ca class=\"md-link\" href=\"https://docs.google.com/spreadsheets/d/1Y8HOtzMYF8cwWqB92FebTu3TLxZ9siHHUTT_H1PWqZM/edit?usp=sharing\" target=\"_blank\" style=\"margin-left: 0; margin-right: 0; display: inline\"\u003ehere\u003c/a\u003e (if the data does turn out to be useful for people, I'll go back and separate it into each night to organize).\n\n\u003ca href=\"/assets/projects/dream_spreadsheet_data.png\" target=\"_blank\"\u003e\u003cimg src=\"/assets/projects/dream_spreadsheet_data.png\" class=\"img-shadow\" style=\"display: block; margin-left: auto; margin-right: auto;\" width=\"500\" alt=\"Dream data spreadsheet\"\u003e\u003c/img\u003e\u003c/a\u003e\n\nBelow you'll see annotated graphs demonstrating the success of the device, recording biometric and EEG trends corresponding with points of interest throughout a night of dreaming.\n\n\u003ca href=\"/assets/projects/DreamGazer%20Early%20Prototype%20with%20MindWave%20-%20Success%20Trial%20Night%201%20-%20Close%20Look%20Chart.png\" target=\"_blank\"\u003e\u003cimg src=\"/assets/projects/DreamGazer%20Early%20Prototype%20with%20MindWave%20-%20Success%20Trial%20Night%201%20-%20Close%20Look%20Chart.png\" class=\"img-shadow\" style=\"display: block; margin-left: auto; margin-right: auto;\" width=\"500\" alt=\"Dream data success trial night 1 graph\"\u003e\u003c/img\u003e\u003c/a\u003e\n\n\u003ca href=\"/assets/projects/DreamGazer%20Early%20Prototype%20with%20MindWave%20-%20Success%20Trial%20Night%202%20(Full%20Log).png\" target=\"_blank\"\u003e\u003cimg src=\"/assets/projects/DreamGazer%20Early%20Prototype%20with%20MindWave%20-%20Success%20Trial%20Night%202%20(Full%20Log).png\" class=\"img-shadow\" style=\"display: block; margin-left: auto; margin-right: auto;\" width=\"500\" alt=\"Dream data success trial night 2 graph\"\u003e\u003c/img\u003e\u003c/a\u003e\n\n\u003ca href=\"/assets/projects/DreamGazer%20Early%20Prototype%20with%20MindWave%20-%20Success%20Trial%20Night%203%20-%20Close%20Look.png\" target=\"_blank\"\u003e\u003cimg src=\"/assets/projects/DreamGazer%20Early%20Prototype%20with%20MindWave%20-%20Success%20Trial%20Night%203%20-%20Close%20Look.png\" class=\"img-shadow\" style=\"display: block; margin-left: auto; margin-right: auto;\" width=\"500\" alt=\"Dream data success trial night 3 graph\"\u003e\u003c/img\u003e\u003c/a\u003e\n\n## The future concept\n\nThe name Dreamgazer refers specifically to a mostly conceptualized, combined VR / AR, EEG, and tDCS (transcranial direct current stimulation) device designed to be 3D printed and then hand-assembled. Dreamgazer's software was planned to be integrated with an AI program (Emoter) that would train users to dream, and guide them through their dreams vocally by talking and responding to biofeedback.\n\n\u003ca href=\"/assets/projects/DreamGazer-3D-Front.png\" target=\"_blank\"\u003e\u003cimg src=\"/assets/projects/DreamGazer-3D-Front.png\" class=\"img-shadow\" style=\"display: block; margin-left: auto; margin-right: auto;\" width=\"500\" alt=\"Dreamgazer 3D front\"\u003e\u003c/img\u003e\u003c/a\u003e\n\n\u003ca href=\"/assets/projects/DreamGazer-Diagram.jpg\" target=\"_blank\"\u003e\u003cimg src=\"/assets/projects/DreamGazer-Diagram.jpg\" class=\"img-shadow\" style=\"display: block; margin-left: auto; margin-right: auto;\" width=\"600\" alt=\"Dreamgazer components diagram\"\u003e\u003c/img\u003e\u003c/a\u003e\n\u003cspan style=\"text-align: center; color: grey; margin-left: auto; margin-right: auto; display: block; width: 80%\"\u003eThe plans were made to be functional, and hand-assembled with proper construction and fabric materials.\u003c/span\u003e\n\n\u003ca href=\"/assets/projects/dreamgazer-intro.png\" target=\"_blank\"\u003e\u003cimg src=\"/assets/projects/dreamgazer-intro.png\" class=\"img-shadow\" style=\"display: block; margin-left: auto; margin-right: auto;\" width=\"500\" alt=\"Dreamgazer VR UI intro\"\u003e\u003c/img\u003e\u003c/a\u003e\n\u003cspan style=\"text-align: center; color: grey; margin-left: auto; margin-right: auto; display: block; width: 80%\"\u003eThe plans were made to be functional, and hand-assembled with proper construction and fabric materials.\u003c/span\u003e\n\n![Dreamgazer VR interface UI demo on youtube](https://www.youtube.com/watch?v=rFekLHHXhHs =100%x315em)\n\u003cspan style=\"text-align: center; color: grey; margin-left: auto; margin-right: auto; display: block; width: 80%\"\u003eDreamgazer was designed with a VR interface, in Unity.\u003c/span\u003e\n\n\u003ca href=\"/assets/projects/DreamGazer-Main-Flowchart.png\" target=\"_blank\"\u003e\u003cimg src=\"/assets/projects/DreamGazer-Main-Flowchart.png\" class=\"img-shadow\" style=\"display: block; margin-left: auto; margin-right: auto;\" width=\"500\" alt=\"DreamGazer main flowchart\"\u003e\u003c/img\u003e\u003c/a\u003e\n\u003cspan style=\"text-align: center; color: grey; margin-left: auto; margin-right: auto; display: block; width: 80%\"\u003eThe full step-by-step process of Dreamgazer's proposed functionality.\u003c/span\u003e\n\nLucid dreaming in wearables and biotechnology is something I will continue exploring. I have plans to further develop and refine new iterations of Dreamgazer, and would like to be able to open-source the hardware and software.\n","ogImage":{"url":"/assets/projects/lucid-dream-data-visualization.png"},"coverImage":"/assets/projects/lucid-dream-data-visualization.png"}},"__N_SSG":true},"page":"/projects/[slug]","query":{"slug":"dreamgazer"},"buildId":"KN6swUZf51tb_txjAh-fx","assetPrefix":"https://jddunn.github.io","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>